{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Read and pre-process my Youtube data"
      ],
      "metadata": {
        "id": "eDotkkOSwI3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the watching history html file"
      ],
      "metadata": {
        "id": "clN-0NXI1JxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "R4tWlb3LvUAf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "\n",
        "# Load and parse the HTML file\n",
        "with open('watch-history.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "video_cells = soup.find_all('div', class_='outer-cell mdl-cell mdl-cell--12-col mdl-shadow--2dp')\n",
        "\n",
        "videos = []\n",
        "for cell in video_cells:\n",
        "    content_cell = cell.find('div', class_='content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1')\n",
        "    \n",
        "    title_element = content_cell.find('a')\n",
        "    title = title_element.text.strip() if title_element else \"\"\n",
        "    video_url = title_element['href'] if title_element else \"\"\n",
        "    \n",
        "    channel_element = content_cell.find('a', href=lambda href: href and '/channel/' in href)\n",
        "    channel = channel_element.text.strip() if channel_element else \"\"\n",
        "    channel_url = channel_element['href'] if channel_element else \"\"\n",
        "    \n",
        "    timestamp = content_cell.contents[-1].strip()\n",
        "    \n",
        "    videos.append({\n",
        "        'Title': title,\n",
        "        'Video URL': video_url,\n",
        "        'Channel': channel,\n",
        "        'Channel URL': channel_url,\n",
        "        'Timestamp': timestamp\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(videos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick data clean to remove NaN values, and clean text data"
      ],
      "metadata": {
        "id": "fQSFmR6hwB5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace('', np.nan, inplace=True)\n",
        "df = df.dropna(subset=['Channel','Title'])"
      ],
      "metadata": {
        "id": "oXpkVhVVwAzz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-process text data"
      ],
      "metadata": {
        "id": "Zq7PWpnC0tMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim import corpora, models\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove punctuations\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove non-English strings\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    # Tokenize the text into individual words\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "    '''# Add custom stopwords\n",
        "    custom_stop_words = ['video', 'min', 'wang']\n",
        "    tokens = [word for word in tokens if word not in custom_stop_words]\n",
        "    '''\n",
        "    # Remove simple letters that are not English words\n",
        "    english_words = set(nltk.corpus.words.words())\n",
        "    tokens = [word for word in tokens if word in english_words]\n",
        "    \n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    \n",
        "    # Join the tokens back into a single string\n",
        "    processed_text = ' '.join(tokens)\n",
        "    return processed_text\n",
        "\n",
        "df_preprocessed = df['Title'].apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqPRoFk00qud",
        "outputId": "53321479-c3d2-4eec-89b3-1891e4f6518d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the cleaned data"
      ],
      "metadata": {
        "id": "ESFyp7071D3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['TitleClean']=df_preprocessed\n",
        "df.to_csv('mydata.csv', index=False)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKlb83lf1F3A",
        "outputId": "dd4fe351-3dfb-4d15-f2b0-81eca9c47619"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6536 entries, 0 to 7191\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Title        6536 non-null   object\n",
            " 1   Video URL    6536 non-null   object\n",
            " 2   Channel      6536 non-null   object\n",
            " 3   Channel URL  6536 non-null   object\n",
            " 4   Timestamp    6536 non-null   object\n",
            " 5   TitleClean   6536 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 357.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get meta data associated with the videos and channels"
      ],
      "metadata": {
        "id": "6J9nw4fo1Wj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get category ID, view counts, like counts, dislike counts, and duration for every video"
      ],
      "metadata": {
        "id": "RRrSQkzXxDRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "youtube_api_key = 'YOUR-API-KEY'\n",
        "\n",
        "video_ID = df['Video URL'].str.split('v=').str[1]\n",
        "video_id_list = list(set(video_ID.to_list()))\n",
        "\n",
        "# Create empty lists to store the extracted information\n",
        "video_ids = []\n",
        "channel_ids = []\n",
        "video_titles = []\n",
        "channel_titles = []\n",
        "category_ids = []\n",
        "view_counts = []\n",
        "like_counts = []\n",
        "dislike_counts = []\n",
        "durations = []\n",
        "\n",
        "# Create YouTube Data API client\n",
        "youtube = build('youtube', 'v3', developerKey=youtube_api_key)\n",
        "\n",
        "# Iterate over each video ID in the DataFrame\n",
        "progress_bar = tqdm(total=len(video_id_list), desc=\"Processing Videos\", unit=\"video\")\n",
        "for video_id in video_id_list:\n",
        "    try:\n",
        "        # Retrieve video details using videos().list() method\n",
        "        video_response = youtube.videos().list(\n",
        "            part='snippet,statistics,contentDetails',\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "\n",
        "        # Extract relevant information from the response\n",
        "        if 'items' in video_response and video_response['items']:\n",
        "            video_data = video_response['items'][0]\n",
        "            snippet = video_data['snippet']\n",
        "            statistics = video_data['statistics']\n",
        "            content_details = video_data['contentDetails']\n",
        "\n",
        "            channel_id = snippet['channelId']\n",
        "            video_title = snippet['title']\n",
        "            channel_title = snippet['channelTitle']\n",
        "            category_id = snippet['categoryId']\n",
        "            view_count = statistics.get('viewCount', 0)\n",
        "            like_count = statistics.get('likeCount', 0)\n",
        "            dislike_count = statistics.get('dislikeCount', 0)\n",
        "            duration = content_details['duration']\n",
        "\n",
        "            # Append the extracted information to the lists\n",
        "            video_ids.append(video_id)\n",
        "            channel_ids.append(channel_id)\n",
        "            video_titles.append(video_title)\n",
        "            channel_titles.append(channel_title)\n",
        "            category_ids.append(category_id)\n",
        "            view_counts.append(view_count)\n",
        "            like_counts.append(like_count)\n",
        "            dislike_counts.append(dislike_count)\n",
        "            durations.append(duration)\n",
        "    except HttpError as e:\n",
        "        print(f\"An error occurred for video ID: {video_id}\")\n",
        "        print(f\"Error message: {e}\")\n",
        "    \n",
        "    # Update the progress bar\n",
        "    progress_bar.update(1)\n",
        "    \n",
        "# Close the progress bar\n",
        "progress_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGp9zLoFwp46",
        "outputId": "60bad429-47b3-4c67-91ed-edd7c7f58051"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Videos: 100%|██████████| 4589/4589 [01:39<00:00, 46.26video/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get category name for each category ID"
      ],
      "metadata": {
        "id": "hM-7_8vuxMCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uni_category_ids = set(category_ids)\n",
        "category_names = {}\n",
        "for category_id in uni_category_ids:\n",
        "    response = youtube.videoCategories().list(\n",
        "        part='snippet',\n",
        "        id=category_id\n",
        "    ).execute()\n",
        "    if 'items' in response:\n",
        "        category_names[category_id] = response['items'][0]['snippet']['title']"
      ],
      "metadata": {
        "id": "e1eLk3o4xOrK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get subscriber count information for each channel"
      ],
      "metadata": {
        "id": "qCuS7O5jxVLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channelIDs = list(set(channel_ids))\n",
        "subscriber_counts = {}\n",
        "for channel_id in channelIDs:\n",
        "    try:\n",
        "        # Retrieve channel statistics using channels().list() method\n",
        "        channel_response = youtube.channels().list(\n",
        "            part='statistics',\n",
        "            id=channel_id\n",
        "        ).execute()        \n",
        "        if 'items' in channel_response and channel_response['items']:\n",
        "            channel_data = channel_response['items'][0]\n",
        "            subscriber_counts[channel_id] = channel_data['statistics'].get('subscriberCount', 0)\n",
        "    except HttpError as e:\n",
        "        print(f\"An error occurred for channel ID: {channel_id}\")\n",
        "        print(f\"Error message: {e}\")"
      ],
      "metadata": {
        "id": "FBnhcTQQxYHC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put all meta data together"
      ],
      "metadata": {
        "id": "DnJTAbIzxoUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_name_list = [category_names.get(category_id, 'N/A') for category_id in category_ids]\n",
        "subscriber_count_list = [subscriber_counts.get(channel_id, 'N/A') for channel_id in channel_ids]\n",
        "data = {\n",
        "    \"VideoID\": video_ids,\n",
        "    \"ChannelID\": channel_ids,\n",
        "    \"CategoryID\": category_ids,\n",
        "    \"VideoTitle\": video_titles,\n",
        "    \"ChannelTitle\": channel_titles,\n",
        "    \"CategoryName\": category_name_list,\n",
        "    \"SubscriberCount\": subscriber_count_list,\n",
        "    \"ViewCount\": view_counts,\n",
        "    \"LikeCount\": like_counts,\n",
        "    \"DislikeCount\": dislike_counts,\n",
        "    \"Duration\": durations\n",
        "}\n",
        "df_meta = pd.DataFrame(data).reset_index()\n",
        "df_meta['Duration'] = pd.to_timedelta(df_meta['Duration']).dt.total_seconds()\n",
        "df_meta.to_csv('video_meta_data.csv',index=False)\n",
        "df_meta.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voLTtCf9xrbV",
        "outputId": "d5a98ad4-a79a-4617-8573-8a6774461f93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4588 entries, 0 to 4587\n",
            "Data columns (total 12 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   index            4588 non-null   int64  \n",
            " 1   VideoID          4588 non-null   object \n",
            " 2   ChannelID        4588 non-null   object \n",
            " 3   CategoryID       4588 non-null   object \n",
            " 4   VideoTitle       4588 non-null   object \n",
            " 5   ChannelTitle     4588 non-null   object \n",
            " 6   CategoryName     4588 non-null   object \n",
            " 7   SubscriberCount  4588 non-null   object \n",
            " 8   ViewCount        4588 non-null   object \n",
            " 9   LikeCount        4588 non-null   object \n",
            " 10  DislikeCount     4588 non-null   int64  \n",
            " 11  Duration         4588 non-null   float64\n",
            "dtypes: float64(1), int64(2), object(9)\n",
            "memory usage: 430.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge df and df_meta"
      ],
      "metadata": {
        "id": "lzZPzECKwnO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df[['Title','TitleClean','Timestamp']].merge(df_meta, left_on='Title', right_on='VideoTitle', how='inner')\n",
        "df_merged = df_merged.loc[:, ~df_merged.columns.str.startswith('Unnamed')]\n",
        "df_merged = df_merged.drop('Title',axis=1)\n",
        "df_merged.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wT12kJrzipc",
        "outputId": "8a06db6a-f3ca-448f-d905-0b804e006d16"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6621 entries, 0 to 6620\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   TitleClean       6621 non-null   object \n",
            " 1   Timestamp        6621 non-null   object \n",
            " 2   index            6621 non-null   int64  \n",
            " 3   VideoID          6621 non-null   object \n",
            " 4   ChannelID        6621 non-null   object \n",
            " 5   CategoryID       6621 non-null   object \n",
            " 6   VideoTitle       6621 non-null   object \n",
            " 7   ChannelTitle     6621 non-null   object \n",
            " 8   CategoryName     6621 non-null   object \n",
            " 9   SubscriberCount  6621 non-null   object \n",
            " 10  ViewCount        6621 non-null   object \n",
            " 11  LikeCount        6621 non-null   object \n",
            " 12  DislikeCount     6621 non-null   int64  \n",
            " 13  Duration         6621 non-null   float64\n",
            "dtypes: float64(1), int64(2), object(11)\n",
            "memory usage: 775.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate more features"
      ],
      "metadata": {
        "id": "X50tjULf2Nzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time features"
      ],
      "metadata": {
        "id": "XftWcGCo9zwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['Timestamp'] = df_merged['Timestamp'].apply(parser.parse)\n",
        "df_merged['Year'] = df_merged['Timestamp'].dt.year\n",
        "df_merged['Month'] = df_merged['Timestamp'].dt.month\n",
        "df_merged['Day'] = df_merged['Timestamp'].dt.day\n",
        "df_merged['Hour'] = df_merged['Timestamp'].dt.hour\n",
        "df_merged['Weekdays'] = np.where(df_merged['Timestamp'].dt.weekday < 5, 0, 1)"
      ],
      "metadata": {
        "id": "pVUxs1H88pBq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video features"
      ],
      "metadata": {
        "id": "2480djED91pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'LikeCount' and 'ViewCount' columns to numeric types\n",
        "df_merged['LikeCount'] = pd.to_numeric(df_merged['LikeCount'], errors='coerce')\n",
        "df_merged['ViewCount'] = pd.to_numeric(df_merged['ViewCount'], errors='coerce')\n",
        "\n",
        "# Calculate the ratio between 'LikeCount' and 'ViewCount'\n",
        "df_merged['LikeViewRatio'] = df_merged['LikeCount'] / df_merged['ViewCount']\n"
      ],
      "metadata": {
        "id": "D7kLrLC3986b"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.to_csv('merged_data.csv',index=False)\n",
        "df_merged.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBj40aOb-7RH",
        "outputId": "437a6b7f-3971-4498-b473-e9f51e6812cd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6621 entries, 0 to 6620\n",
            "Data columns (total 20 columns):\n",
            " #   Column           Non-Null Count  Dtype                                \n",
            "---  ------           --------------  -----                                \n",
            " 0   TitleClean       6621 non-null   object                               \n",
            " 1   Timestamp        6621 non-null   datetime64[ns, tzoffset(None, 14400)]\n",
            " 2   index            6621 non-null   int64                                \n",
            " 3   VideoID          6621 non-null   object                               \n",
            " 4   ChannelID        6621 non-null   object                               \n",
            " 5   CategoryID       6621 non-null   object                               \n",
            " 6   VideoTitle       6621 non-null   object                               \n",
            " 7   ChannelTitle     6621 non-null   object                               \n",
            " 8   CategoryName     6621 non-null   object                               \n",
            " 9   SubscriberCount  6621 non-null   object                               \n",
            " 10  ViewCount        6621 non-null   int64                                \n",
            " 11  LikeCount        6621 non-null   int64                                \n",
            " 12  DislikeCount     6621 non-null   int64                                \n",
            " 13  Duration         6621 non-null   float64                              \n",
            " 14  Year             6621 non-null   int64                                \n",
            " 15  Month            6621 non-null   int64                                \n",
            " 16  Day              6621 non-null   int64                                \n",
            " 17  Hour             6621 non-null   int64                                \n",
            " 18  Weekdays         6621 non-null   int64                                \n",
            " 19  LikeViewRatio    6621 non-null   float64                              \n",
            "dtypes: datetime64[ns, tzoffset(None, 14400)](1), float64(2), int64(9), object(8)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    }
  ]
}